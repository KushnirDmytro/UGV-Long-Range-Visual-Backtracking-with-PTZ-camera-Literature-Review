@article{wang_survey_2024,
  title = {A Survey on Path Planning for Autonomous Ground Vehicles in Unstructured Environments},
  author = {Wang, Nan and Li, Xiang and Zhang, Kanghua and Wang, Jixin and Xie, Dongxuan},
  journal = {Machines},
  volume = {12},
  number = {1},
  pages = {31},
  year = {2024},
  doi = {10.3390/machines12010031},
  url = {https://www.mdpi.com/2075-1702/12/1/31},
  abstract = {Comprehensive review of path planning techniques for UGVs in unstructured environments, focusing on traversability analysis, terrain constraints, and cost estimation. Highlights gaps in existing methods.},
  keywords = {Path Planning, Unstructured Environments, Terrain Analysis}
}

@article{kushnir_ugv_nodate,
  title = {UGV Backtracking Recovery with Active Visual Landmarks-Based Navigation},
  author = {Kushnir, Dmytro},
  abstract = {Explores the use of PTZ cameras in UGV navigation, focusing on dynamic landmark detection, recognition, and topological map generation. Discusses operational constraints and algorithms for distant landmark recognition.},
  keywords = {PTZ Cameras, Visual Landmarks, Backtracking, Navigation}
}

@article{hausler2024towards,
  title={Towards long-term robotics in the wild},
  author={Hausler, S. and Griffiths, E. and Ramezani, M. and Moghadam, P.},
  journal={arXiv preprint arXiv:2404.18477},
  year={2024},
  note={Discusses modular and long-term systems for robotics in unstructured environments, emphasizing iterative approaches.},
  url={https://arxiv.org/abs/2404.18477}
}

@article{ros_modularity,
  title={Robot Operating System (ROS): The Complete Reference (Volume 2)},
  author={Quigley, Morgan and Gerkey, Brian and Smart, William D.},
  journal={Springer},
  year={2020},
  note={Key reference for modular and open-source system design in robotics.},
  doi={10.1007/978-3-030-20190-6},
  url={https://link.springer.com/book/10.1007/978-3-030-20190-6}
}

@article{guastella_learning-based_2020,
  title = {Learning-Based Methods of Perception and Navigation for Ground Vehicles in Unstructured Environments: A Review},
  author = {Guastella, Dario Calogero and Muscato, Giovanni},
  journal = {Sensors},
  volume = {21},
  number = {1},
  pages = {73},
  year = {2020},
  doi = {10.3390/s21010073},
  url = {https://www.mdpi.com/1424-8220/21/1/73},
  abstract = {Review of learning-based methods for environment perception and navigation in unstructured environments, focusing on search and rescue, planetary exploration, and agricultural robotics.},
  keywords = {Learning-Based Methods, Navigation, Perception, Unstructured Environments}
}

@inproceedings{murali_active_2016,
  title = {Active Planning Based Extrinsic Calibration of Exteroceptive Sensors in Unknown Environments},
  author = {Murali, Varun and Nieto, Carlos and Choudhary, Siddharth and Christensen, Henrik I.},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages = {2498--2505},
  year = {2016},
  doi = {10.1109/IROS.2016.7759389},
  url = {http://ieeexplore.ieee.org/document/7759389/},
  abstract = {Proposes an algorithm for autonomous extrinsic calibration of exteroceptive sensors, reducing manual effort and human error in SLAM systems.},
  keywords = {Sensor Calibration, SLAM, Autonomous Calibration}
}

@misc{min_autonomous_2024,
  title = {Autonomous Driving in Unstructured Environments: How Far Have We Come?},
  author = {Min, Chen and Si, Shubin and Wang, Xu et al.},
  publisher = {arXiv},
  year = {2024},
  doi = {10.48550/arXiv.2410.07701},
  url = {http://arxiv.org/abs/2410.07701},
  abstract = {Survey of over 250 papers on autonomous driving in unstructured environments, addressing perception, path planning, and dataset challenges. Provides an active repository for ongoing research.},
  keywords = {Autonomous Driving, Unstructured Environments, Datasets}
}

@misc{lim_similar_2024,
  title = {Similar but Different: A Survey of Ground Segmentation and Traversability Estimation for Terrestrial Robots},
  author = {Lim, Hyungtae and Oh, Minho and Lee, Seungjae et al.},
  publisher = {arXiv},
  year = {2024},
  doi = {10.48550/arXiv.2312.16839},
  url = {http://arxiv.org/abs/2312.16839},
  abstract = {Clarifies distinctions between ground segmentation and traversability estimation, surveying literature on techniques and their applications for terrestrial robots.},
  keywords = {Traversability, Ground Segmentation, Terrestrial Robots}
}

@article{beycimen_comprehensive_2023,
  title = {A Comprehensive Survey of Unmanned Ground Vehicle Terrain Traversability for Unstructured Environments and Sensor Technology Insights},
  author = {Beycimen, Semih and Ignatyev, Dmitry and Zolotas, Argyrios},
  journal = {Engineering Science and Technology, an International Journal},
  volume = {47},
  pages = {101457},
  year = {2023},
  doi = {10.1016/j.jestch.2023.101457},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2215098623001350},
  abstract = {Categorizes terrain traversability methods and explores sensor technologies used for UGVs in unstructured environments. Discusses mixed-method approaches for improved performance.},
  keywords = {Terrain Traversability, Sensor Technologies, UGVs}
}

@article{wijayathunga_challenges_2023,
  title = {Challenges and Solutions for Autonomous Ground Robot Scene Understanding and Navigation in Unstructured Outdoor Environments: A Review},
  author = {Wijayathunga, Liyana and Rassau, Alexander and Chai, Douglas},
  journal = {Applied Sciences},
  volume = {13},
  number = {17},
  pages = {9877},
  year = {2023},
  doi = {10.3390/app13179877},
  url = {https://www.mdpi.com/2076-3417/13/17/9877},
  abstract = {Comprehensive review on navigation and scene understanding methods for unstructured outdoor environments, discussing hybrid approaches and sensor fusion.},
  keywords = {Scene Understanding, Navigation, Unstructured Environments}
}

@misc{seo_safe_2023,
  title = {Safe Navigation in Unstructured Environments by Minimizing Uncertainty in Control and Perception},
  author = {Seo, Junwon and Mun, Jungwi and Kim, Taekyung},
  publisher = {arXiv},
  year = {2023},
  doi = {10.48550/arXiv.2306.14601},
  url = {http://arxiv.org/abs/2306.14601},
  abstract = {Proposes a framework for uncertainty-aware navigation in unstructured environments, integrating vehicle dynamics and traversability models.},
  keywords = {Uncertainty-Aware Navigation, Traversability, Vehicle Dynamics}
}


@article{vidanapathirana_wildscenes_2024,
	title = {{WildScenes}: {A} {Benchmark} for {2D} and {3D} {Semantic} {Segmentation} in {Large}-scale {Natural} {Environments}},
	issn = {0278-3649, 1741-3176},
	shorttitle = {{WildScenes}},
	url = {http://arxiv.org/abs/2312.15364},
	doi = {10.1177/02783649241278369},
	abstract = {Recent progress in semantic scene understanding has primarily been enabled by the availability of semantically annotated bi-modal (camera and LiDAR) datasets in urban environments. However, such annotated datasets are also needed for natural, unstructured environments to enable semantic perception for applications, including conservation, search and rescue, environment monitoring, and agricultural automation. Therefore, we introduce WildScenes, a bimodal benchmark dataset consisting of multiple large-scale, sequential traversals in natural environments, including semantic annotations in high-resolution 2D images and dense 3D LiDAR point clouds, and accurate 6-DoF pose information. The data is (1) trajectory-centric with accurate localization and globally aligned point clouds, (2) calibrated and synchronized to support bi-modal training and inference, and (3) containing different natural environments over 6 months to support research on domain adaptation. Our 3D semantic labels are obtained via an efficient, automated process that transfers the human-annotated 2D labels from multiple views into 3D point cloud sequences, thus circumventing the need for expensive and time-consuming human annotation in 3D. We introduce benchmarks on 2D and 3D semantic segmentation and evaluate a variety of recent deep-learning techniques to demonstrate the challenges in semantic segmentation in natural environments. We propose train-val-test splits for standard benchmarks as well as domain adaptation benchmarks and utilize an automated split generation technique to ensure the balance of class label distributions. The WildScenes benchmark webpage is https://csiro-robotics.github.io/WildScenes, and the data is publicly available at WildScenes Benchmark Dataset.},
	language = {en},
	urldate = {2025-01-10},
	journal = {The International Journal of Robotics Research},
	author = {Vidanapathirana, Kavisha and Knights, Joshua and Hausler, Stephen and Cox, Mark and Ramezani, Milad and Jooste, Jason and Griffiths, Ethan and Mohamed, Shaheer and Sridharan, Sridha and Fookes, Clinton and Moghadam, Peyman},
	month = sep,
	year = {2024},
	note = {arXiv:2312.15364 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	pages = {02783649241278369},
	annote = {Comment: Accepted in the The International Journal of Robotics Research (IJRR)},
}
